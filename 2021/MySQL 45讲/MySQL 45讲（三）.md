[TOC]

# 事务隔离（二）

```sql
mysql> CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `k` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB;
insert into t(id, k) values(1,1),(2,2);
```



| Transaction A                                 | Transaction B                                                | Transaction C                      |
| --------------------------------------------- | ------------------------------------------------------------ | ---------------------------------- |
| `start transaction with consistent snapshot;` |                                                              |                                    |
|                                               | `start transaction with consistent snapshot;`                |                                    |
|                                               |                                                              | `update t set k=k+1 where id = 1;` |
|                                               | `update t set k=k+1 where id = 1;`<br>`select k from t where id = 1;` |                                    |
| `select k from t where id = 1;`<br>`commit;`  |                                                              |                                    |
|                                               | `commit;`                                                    |                                    |

`begin/start transaction` 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句，事务才真正启动。如果你想要马上启动一个事务，可以使用 `start transaction with consistent snapshot` 这个命令。

> 第一种启动方式，一致性视图是在第执行第一个快照读语句时创建的； 第二种启动方式，一致性视图是在执行 start transaction with consistent snapshot 时创建的。

- 在MySQL中，有两个“视图”的概念：
  1. 一个是 `view`。它是一个用查询语句定义的**虚拟表**，**在调用的时候执行查询语句并生成结果**。创建视图的语法是 `create view …` ，而它的查询方法与表一样。
  2. 另一个是InnoDB在实现MVCC 时用到的一致性读视图，即 `consistent read view`，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现。它**没有物理结构**，作用是事务执行期间用来定义“我能看到什么数据”。

## “快照”在MVCC里的工作

- 在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。注意，这个快照是**基于整库**的。
- InnoDB 里面每个事务有一个唯一的事务 ID，叫作 `transaction id`。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。
- 每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 `transaction id` 赋值给这个数据版本的事务 ID，记为 `row trx_id`。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。也就是说，数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 `row trx_id`。
- MVCC中每个版本都是根据当前版本和`undo log`计算出来的。
- 按照**可重复读**的定义，**一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这个事务执行期间，其他事务的更新对它不可见。**

### 视图数组

- 在实现上，InnoDB为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务ID。“活跃”指的就是，启动了但还没提交。
- 数组里面事务ID的最小值记为低水位，当前系统里面已经创建过的事务ID的最大值加1记为高水位。这个视图数组和高水位，就组成了当前事务的一致性视图。
- 数据版本的可见性规则，就是基于数据的`row trx_id`和这个一致性视图的对比结果得到的。

对于当前事务的启动瞬间（未提交事务）来说，一个数据版本的`row trx_id`，有以下几种可能：

1. 如果是落在低水位之前，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是**可见**的；
2. 如果是落在高水位之后，表示这个版本是由将来启动的事务生成的，这个事务肯定是不可见的。
3. 如果是落在中间，那就包含两种情况：
   1. 如果`row trx_id`在数组中，表示这个版本是由还没提交的事务生成的，**不可见**；
   2. 如果`row trx_id`不在数组中，表示这个版本是已经提交了的事务生成的，**可见**。

- 一个版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：
  1. 版本未提交，不可见；
  2. 版本已提交，但是是在视图创建后提交的，不可见；
  3. 版本已提交，而且是在视图创建前提交的，可见。

## 更新逻辑

- **更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”。**
- **读提交和可重复读：**
  - 可重复读的隔离级别下，只需要在事务开始时创建统一视图，之后事务里的其他查询都共用这个一致性视图。
  - 在读提交的隔离级别下，每一个语句执行前都会重新算出一个新的视图。

# 普通索引和唯一索引

## 查询过程

- 由于InnoDB的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在InnoDB中，每个数据页的大小默认是16KB。
- InnoDB的数据是按数据页为单位来读写的。也就是说，当需要读一条记录时，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在InnoDB中，每个数据页的大小默认是16KB。
- 引擎是按页读写的，所以当在索引树上查找，第一次找到相应记录时，它所在的数据页就都在内存里了。那么对于普通索引来说，要多做的那一次“查找和判断下一条记录”的操作，就只需要一次指针寻找和一次计算。如果查找到的记录刚好是这个数据页的最后一个记录，那么要取下一个记录，必须读取下一个数据页，这个操作会稍微复杂一些。
- 但是，我们之前计算过，对于整型字段，一个数据页可以放近千个key，因此出现这种情况的概率会很低。所以，我们计算平均性能差异时，仍可以认为这个操作成本对于现在的CPU来说可以忽略不计。所以**对于查询过程，普通索引和唯一索引的性能差别不大。**

## 更新过程

### `change buffer`

- 当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB会将这些更新操作缓存在`change buffer`中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行`change buffer`中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。
- 虽然叫`change buffer`，实际上它是可以持久化的数据。也就是说，`change buffer`在内存中有拷贝，也会被写入到磁盘上。
- **将`change buffer`中的操作应用到原数据页，得到最新结果的过程**称为`merge`。除了访问这个数据页会触发`merge`外，系统有后台线程会定期`merge`。在数据库正常关闭（`shutdown`）的过程中，也会执行`merge`操作。
- 若能够将更新操作先记录在`change buffer`，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用`buffer pool`的，所以这种方式还能够避免占用内存，提高内存利用率。

### `change buffer`特点

- 对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。通过唯一索引更新的时候，若是已经通过索引，将数据页读入内存判断记录，那么此时直接更新内存会更快，没必要使用`change buffer`了。
- `change buffer`用的是`buffer pool`里的内存，因此不能无限增大。`change buffer`的大小，可以通过参数`innodb_change_buffer_max_size`来动态设置的。当这个参数设置为50的时候，表示`change buffer`的大小最多只能占用`buffer pool`的50%。

#### 表记录更新-插入过程

1. 记录要更新的目标页在内存中。
   - 唯一索引：判断插入位置有没有冲突，没有就插入这个值，语句执行结束。
   - 普通索引：找到位置，直接插入这个值，语句执行结束。
   
   > 普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的CPU时间。
   
2. 记录要更新的目标页不在内存中。

   - 唯一索引：需要将数据页读取到内存中，判断到没有冲突，插入这个值，语句就执行结束了。
   - 普通索引：更新记录到`change buffer`，语句就执行结束了。

   > 将数据从磁盘读入内存涉及随机IO的访问，是数据库里面成本最高的操作之一。`change buffer`因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。

## `change buffer`使用场景

- `merger`的时候是真正进行数据更新的时刻，而`change buffer`的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做`merge`之前，`change buffer`记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。

- 因此对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时`change buffer`的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。
- 反之，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在`change buffer`，但之后由于马上要访问这个数据页，会立即触发`merge`过程。这样随机访问IO的次数不会减少，反而增加了`change buffer`的维护代价。所以，对于这种业务模式来说，`change buffer`反而起到了副作用。

## 索引选择和实践

- 普通索引和唯一索引的选择：两类索引在查询能力上没有多大的差别，主要考虑的是对更新性能的影响。所以，尽量选择普通索引。
- 如果所有的更新后面，都马上伴随着对这个记录的更新，那么你应该关闭`change buffer`。而在其他情况下，`change buffer`都能提升更新性能。
- 实际使用中，你会发现，普通索引和`change buffer`的配合使用，对于数据量大的表的更新优化还是很明显的。
- 尤其是在使用机械硬盘时，`change buffer`这个机制的收效是非常显著的。所以当你有一个类似“历史数据”的库，并且处于成本考虑用的是机械硬盘时，那你应该特别关注这些表里的索引，尽量使用普通索引，然后把`change buffer`尽量开大，以确保这个“历史数据”表的数据写入速度。

## `redo log`和 `change buffer`

```mysql
mysql > insert into t(id, k) values(id1, k1),(id2,k2)
```

这里，假设当前k索引树的状态，查找到位置后，k1所在的数据页在内存（InnoDB buffer pool）中，k2所在的数据页不在内存中。

分析更新语句，包含下图所展示的四个部分：**内存**、**redo log**、**数据表空间**、**系统表空间**。

![](https://cdn.jsdelivr.net/gh/Bruce0hh/Bruce0hh.github.io/pic-bed/20220811010241.png)

**按图所示顺序：**

1. Page1在内存中，直接更新内存；
2. Page2没有在内存中，就在内存的`change buffer`区域，记录下“我要往Page2插入一行”这个信息。
3. 将上述两个动作记入`redo log`中。

做完上面这些，事务就可以完成了。所以，执行这条更新语句的成本很低，就是写了两处内存，然后写了一出磁盘（两次操作合在一起写了一次磁盘），而且还是顺序写的。同时，图中的两个虚线箭头，是后台操作，不影响更新的响应时间。

```mysql
select * from where k in (k1,k2)
```

**后续读请求处理：**

如果读语句发生在更新语句后不久，内存中的数据都还在，那么此时的这两个读操作就与**系统表空间**和`redo log`无关了。

![](https://cdn.jsdelivr.net/gh/Bruce0hh/Bruce0hh.github.io/pic-bed/20220811010334.png)

1. 读Page1的时候，直接从内存返回。
2. 要读Page2的时候，需要把Page2从磁盘读入内存中，然后应用`change buffer`里面的操作日志，生成一个正确的版本并返回结果。
3. 直到需要读Page2的时候，这个数据页才会被读入内存。

> 所以，如果要简单地对比这两个机制在提升更新性能上的收益的话，`redo log`主要节省的事随机写磁盘的IO消耗（转成顺序写），而`change buffer`主要节省的则是随机读磁盘的IO消耗。

### change buffer机制与异常

> 如果某次写入使用了`change buffer`机制，之后主机异常重启，是否会丢失`change buffer`和数据

- 不会丢失
- 虽然只是更新内存，但是在事务提交的时候，我们把`change buffer`的操作也记录到`redo log`里了，所以崩溃恢复的时候，`change buffer`也能找回来。

> `merge`的过程是否会把数据直接写回磁盘

`merge`流程：

1. 从磁盘读入数据页到内存（老版本的数据页）；
2. 从`change buffer`里找出这个数据页的`change buffer`记录，依次应用，得到新版的数据页；
3. 写`redo log`。这个`redo log`包含了数据的变更和`change buffer`的变更。

此时，数据页和内存中`change buffer`对应的磁盘位置都还没有修改，属于脏页，之后各自刷回自己的物理数据。

