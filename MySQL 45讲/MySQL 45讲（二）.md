[TOC]

# 深入浅出索引

> **索引的出现其实就是为了提高数据查询的效率，就像书的目录一样**。

## 索引常见模型

### 哈希表

- 键值对存储的结构。
- 通常使用拉链法解决哈希冲突。
- 由于哈希表不是有序的，哈希索引做区间查询速度很慢。
- 哈希表结构适用于只有等值查询的场景。

### 有序数组

- 查询效率极高，但是更新数据太麻烦，当往中间插入一个值时，后续的记录都要移动，成本太高。
- 有序数组结构只适用于静态引擎，内部的表几乎不会修改。

### 搜索树

- 为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N 叉”树。这里，“N 叉”树中的“N”取决于数据块的大小。

## `InnoDB`的索引模型

每一个索引在`InnoDB`里面对应一棵**B+树**。

- 主键索引的叶子节点存的是整行数据。在`InnoDB`里，主键索引被称为聚簇索引。
- 非主键索引的叶子节点内容是主键的值。在`InnoDB`里，非主键索引也被称为二级索引。
- 基于非主键的索引需要多扫描一棵索引树，**回到主键索引树搜索的过程，我们称为回表**。

## 索引维护

- B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。如果新值所在的数据页满了，根据B+树算法，这时需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。
- 除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。
- 自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。而用业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。
- **主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。**所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。

- 业务字段主键的使用场景（KV场景）
  1. 只有一个索引。
  2. 该索引必须是唯一索引。

## 覆盖索引

- **由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。**
- 关键字**and**的连接不会影响索引的顺序。即`select * from where c1 = x and c2 =x`，同样可以使用联合索引`(c2, c1)`。
- 若某列字段没有条件，会导致后面的列都无法使用索引。
- `or` 条件的字段必须是独立索引，否则索引无效。
- `order by` 和 `group by` 类似，字段顺序与索引一致时，会使用索引排序；字段顺序与索引不一致时，不使用索引。
- **范围查询**（`select * from where c1 = x and c2 =x`，联合索引`(c2, c1, c3`）
  1. 当`select * from where c2 > 1 and c2 < 5`，此时联合索引**可用**。
  2. 当`select * from where c2 = 1 and c1 > 5`，此时由于范围查询的 c1 左侧的值确定，所以联合索引**可用**。
  3. 当`select * from where c2 > 1 and c3 > 5`，此时由于 c1 的值不确定，所以索引**不可用**。 

## 最左前缀原则

- **B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。**
- **第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。**

## 索引下推

- MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引（**联合索引**）遍历过程中，对**索引中包含的字段先做判断**，直接过滤掉不满足条件的记录，减少回表次数。

## 索引例子

```sql
-- 表内已有a,b做联合主键
-- 对于以下两条SQL，需要ca，cb两个联合索引吗？

select * from geek where c=N order by a limit 1; --A
select * from geek where c=N order by b limit 1; --B
```

a,b做联合主键，在InnoDB的聚簇索引中相当于**先以a排序再以b排序**。

- 对于A语句，当使用c查询，再通过ab索引就可以使用索引查询，所以不需要ca索引。
- 反之，对于B语句，使用c查询后，需要通过b查询，但是b的顺序以a为准，所以还需要cb索引。



# 全局锁和表锁

## 全局锁

- 全局锁就是对整个数据库实例加锁。
- MySQL 提供了一个加全局读锁的方法，命令是 `Flush tables with read lock (FTWRL)`。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。
- 全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都 select 出来存成文本。通过 `FTWRL` 确保不会有其他线程对数据库做更新，然后对整个库做备份。注意，在备份过程中整个库完全处于只读状态。
- 只读的问题：
  - 如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；
  - 如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 `binlog`，会导致主从延迟。
- 官方自带的逻辑备份工具是 `mysqldump`。当 `mysqldump` 使用参数`–single-transaction` 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。
- **single-transaction 方法只适用于所有的表使用事务引擎的库。**如果有的表使用了不支持事务的引擎，那么备份就只能通过 `FTWRL` 方法。这往往是 DBA 要求业务开发人员使用 InnoDB 替代 MyISAM 的原因之一。
- **`set global readonly=true` 的方式**，也可以让全库进入只读状态，但我还是会建议你用 FTWRL 方式，主要有两个原因：
  1. 在有些系统中，`readonly` 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 `global` 变量的方式影响面更大，我不建议你使用。
  2. 在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 `readonly` 之后，如果客户端发生异常，则数据库就会一直保持 `readonly` 状态，这样会导致整个库长时间处于不可写状态，风险较高。
- 业务的更新不只是增删改数据（DML)，还有可能是加字段等修改表结构的操作（DDL）。不论是哪种方法，一个库被全局锁上以后，你要对里面任何一个表做加字段操作，都是会被锁住的。

## 表级锁

### 表锁

> lock tables … read/write

- 与 `FTWRL` 类似，可以用 `unlock tables` 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，`lock tables` 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。

### 元数据锁（metadata lock）

- MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。
- 在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。
  - 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。
  - 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。

- 事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。表示当表中含有读锁时，写请求进来时会被堵塞，而且事务结束前不会释放，这就导致后来的读请求会因此堵塞。
- 安全地给小表加字段：
  1. 要解决长事务，事务不提交，就会一直占着 MDL 锁。在 MySQL 的 `information_schema` 库的 `innodb_trx` 表中，你可以查到当前执行中的事务。如果你要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。
  2. 如果你要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，而你**不得不加个字段**，你该怎么做呢？比较理想的机制是，在 `alter table` 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。

# 行锁

> 行锁就是针对数据表中行记录的锁。这很好理解，比如事务 A 更新了一行，而这时候事务 B 也要更新同一行，则必须等事务 A 的操作完成后才能进行更新。

### 两阶段锁

- **在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。**
- **优化例子**：
  1. 对于事务A有3个操作：update小表，update大表，insert记录。
  2. 应该将update大表记录放最后，因为**大表的操作频繁**，所以需要让该表的**行锁的持续时间尽量短。**
  3. 综上所述，**如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁的申请时机尽量往后放。**

### 死锁

| Transaction A                                  | Transaction B                      |
| ---------------------------------------------- | ---------------------------------- |
| `begin;`<br>`update t set k=k+1 where id = 1;` | `begin;`                           |
|                                                | `update t set k=k+1 where id = 2`  |
| `update  t set k=k+1 where id = 2;`            |                                    |
|                                                | `update t set k=k+1 where id = 1;` |

#### 释放死锁

**两种策略：**

1. **直接进入等待，直到超时**。这个超时时间可以通过参数 `innodb_lock_wait_timeout` 来设置。
   - 在 InnoDB 中，`innodb_lock_wait_timeout` 的默认值是 50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受的。
   - 但是，我们又不可能直接把这个时间设置成一个很小的值，比如 1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多误伤。
2. 另一种策略是，发起**死锁检测**，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 `innodb_deadlock_detect` 设置为 on，表示开启这个逻辑。
   - 每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 $O(n^2)$ 的操作。
   - 假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。因此，你就会看到 CPU 利用率很高，但是每秒却执行不了几个事务。

#### 热点行更新问题

1. 如果你能确保这个业务一定不会出现死锁，可以**临时把死锁检测关掉**。但是这种操作本身带有一定的风险，关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。
2. 如果并发能够控制住，比如同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。**并发控制要做在数据库服务端。**如果你有中间件，可以考虑在中间件实现；如果你的团队有能修改 MySQL 源码的人，也可以做在 MySQL 里面。基本思路就是，**对于相同行的更新，在进入引擎之前排队。这样在 InnoDB 内部就不会有大量的死锁检测工作了。**
3. **可以考虑通过将一行改成逻辑上的多行来减少锁冲突。**以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1/10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗。**这类方案需要根据业务逻辑做详细设计，代码要有特殊处理。**

#### 多行数据操作

- 如果你要删除一个表里面的前 10000 行数据：
  1. 直接执行 `delete from T limit 10000;`
  2. 在一个连接中循环执行 20 次 `delete from T limit 500;`
  3. 在 20 个连接中同时执行 `delete from T limit 500。`

- 第二种方式是相对较好的。
- 第一种方式（即：直接执行 delete from T limit 10000）里面，单个语句占用时间长，锁的时间也比较长；而且大事务还会导致主从延迟。
- 第三种方式（即：在 20 个连接中同时执行 delete from T limit 500），会人为造成锁冲突。





